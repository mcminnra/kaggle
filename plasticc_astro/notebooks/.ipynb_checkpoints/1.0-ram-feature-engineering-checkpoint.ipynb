{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Baseline: 2.25/\n",
    "\n",
    "## Ideas\n",
    "- polynomial 2 - capture interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client, LocalCluster, progress\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_plus(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    #Convert decimal degrees to Radians:\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon2 = np.radians(lon2)\n",
    "    lat2 = np.radians(lat2)\n",
    "\n",
    "    #Implementing Haversine Formula: \n",
    "    dlon = np.subtract(lon2, lon1)\n",
    "    dlat = np.subtract(lat2, lat1)\n",
    "\n",
    "    a = np.add(np.power(np.sin(np.divide(dlat, 2)), 2),  \n",
    "                          np.multiply(np.cos(lat1), \n",
    "                                      np.multiply(np.cos(lat2), \n",
    "                                                  np.power(np.sin(np.divide(dlon, 2)), 2))))\n",
    "    \n",
    "    haversine = np.multiply(2, np.arcsin(np.sqrt(a)))\n",
    "    latlon1 = np.subtract(np.multiply(lon1, lat1), np.multiply(lon2, lat2))\n",
    "    \n",
    "    return haversine, latlon1\n",
    "\n",
    "\n",
    "def generate_meta_features(df_tmp):\n",
    "    '''Function to engineer meta features\n",
    "    '''\n",
    "    df_tmp['haversine'], df_tmp['latlon1'] = haversine_plus(df_tmp['ra'].values,\n",
    "                                                    df_tmp['decl'].values,\n",
    "                                                    df_tmp['gal_l'].values,\n",
    "                                                    df_tmp['gal_b'].values)\n",
    "    \n",
    "    return df_tmp\n",
    "\n",
    "\n",
    "def generate_features(df_tmp, df_out):\n",
    "    '''Function to engineer features\n",
    "    '''\n",
    "    # Generate Flux Features\n",
    "    df_tmp['flux_ratio_sq'] = np.power(df_tmp['flux'] / df_tmp['flux_err'], 2.0)\n",
    "    df_tmp['flux_by_flux_ratio_sq'] = df_tmp['flux'] * df_tmp['flux_ratio_sq']\n",
    "    \n",
    "    '''\n",
    "    flux & flux_err - by object_id\n",
    "    '''\n",
    "    ## By object_id\n",
    "    flux_mean = df_tmp.groupby(['object_id'])['flux'].mean()  # Mean (NOTE FIGURE OUT HOW TO ADD '_MEAN' to DF)\n",
    "    flux_median = df_tmp.groupby(['object_id'])['flux'].median() # Median\n",
    "    flux_std = df_tmp.groupby(['object_id'])['flux'].std()  # Std. Dev.\n",
    "    flux_max = df_tmp.groupby(['object_id'])['flux'].max()  # Max\n",
    "    flux_min = df_tmp.groupby(['object_id'])['flux'].min()  # Min\n",
    "    flux_skew = df_tmp.groupby(['object_id'])['flux'].skew()  # Skew\n",
    "    flux_kurtosis = df_tmp.groupby(['object_id'])['flux'].apply(pd.DataFrame.kurtosis)  # Kurtosis\n",
    "    # Flux Err\n",
    "    flux_err_mean = df_tmp.groupby(['object_id'])['flux_err'].mean()  # Mean (NOTE FIGURE OUT HOW TO ADD '_MEAN' to DF)\n",
    "    flux_err_median = df_tmp.groupby(['object_id'])['flux_err'].median()  # Median\n",
    "    flux_err_std = df_tmp.groupby(['object_id'])['flux_err'].std()  # Std. Dev\n",
    "    flux_err_max = df_tmp.groupby(['object_id'])['flux_err'].max()  # Max\n",
    "    flux_err_min = df_tmp.groupby(['object_id'])['flux_err'].min()  # Min\n",
    "    flux_err_skew = df_tmp.groupby(['object_id'])['flux_err'].skew()  # Skew\n",
    "    flux_err_kurtosis = df_tmp.groupby(['object_id'])['flux_err'].apply(pd.DataFrame.kurtosis)  # Kurtosis\n",
    "    \n",
    "    df_out = df_out.join(flux_mean, on='object_id', how='inner', rsuffix='_mean')\n",
    "    df_out = df_out.join(flux_median, on='object_id', how='inner', rsuffix='_median')\n",
    "    df_out = df_out.join(flux_std, on='object_id', how='inner', rsuffix='_std')\n",
    "    df_out = df_out.join(flux_max, on='object_id', how='inner', rsuffix='_max')\n",
    "    df_out = df_out.join(flux_min, on='object_id', how='inner', rsuffix='_min')\n",
    "    df_out = df_out.join(flux_skew, on='object_id', how='inner', rsuffix='_skew')\n",
    "    df_out = df_out.join(flux_kurtosis, on='object_id', how='inner', rsuffix='_kurtosis')\n",
    "\n",
    "    df_out = df_out.join(flux_err_mean, on='object_id', how='inner', rsuffix='_mean')\n",
    "    df_out = df_out.join(flux_err_median, on='object_id', how='inner', rsuffix='_median')\n",
    "    df_out = df_out.join(flux_err_std, on='object_id', how='inner', rsuffix='_std')\n",
    "    df_out = df_out.join(flux_err_max, on='object_id', how='inner', rsuffix='_max')\n",
    "    df_out = df_out.join(flux_err_min, on='object_id', how='inner', rsuffix='_min')\n",
    "    df_out = df_out.join(flux_err_skew, on='object_id', how='inner', rsuffix='_skew')\n",
    "    df_out = df_out.join(flux_err_kurtosis, on='object_id', how='inner', rsuffix='_kurtosis')\n",
    "\n",
    "    '''\n",
    "    flux & flux_err - by object_id, then by passband\n",
    "    '''\n",
    "    # Flux\n",
    "    flux_mean = df_tmp.groupby(['object_id', 'passband'])['flux'].mean().unstack(level='passband').add_suffix('_mean')  # Mean\n",
    "    flux_median = df_tmp.groupby(['object_id', 'passband'])['flux'].median().unstack(level='passband').add_suffix('_median')  # Median\n",
    "    flux_std = df_tmp.groupby(['object_id', 'passband'])['flux'].std().unstack(level='passband').add_suffix('_std')  # Std. Dev.\n",
    "    flux_max = df_tmp.groupby(['object_id', 'passband'])['flux'].max().unstack(level='passband').add_suffix('_max')  # Max\n",
    "    flux_min = df_tmp.groupby(['object_id', 'passband'])['flux'].min().unstack(level='passband').add_suffix('_min')  # Min\n",
    "    flux_skew = df_tmp.groupby(['object_id', 'passband'])['flux'].skew().unstack(level='passband').add_suffix('_skew')  # Skew\n",
    "    flux_kurtosis = df_tmp.groupby(['object_id', 'passband'])['flux'].apply(pd.DataFrame.kurtosis).unstack(level='passband').add_suffix('_kurtosis')  # Kurtosis\n",
    "    # Flux Err\n",
    "    flux_err_mean = df_tmp.groupby(['object_id', 'passband'])['flux_err'].mean().unstack(level='passband').add_suffix('_err_mean')  # Mean\n",
    "    flux_err_median = df_tmp.groupby(['object_id', 'passband'])['flux_err'].median().unstack(level='passband').add_suffix('_err_median')  # Median\n",
    "    flux_err_std = df_tmp.groupby(['object_id', 'passband'])['flux_err'].std().unstack(level='passband').add_suffix('_err_std')  # Std. Dev\n",
    "    flux_err_max = df_tmp.groupby(['object_id', 'passband'])['flux_err'].max().unstack(level='passband').add_suffix('_err_max')  # Max\n",
    "    flux_err_min = df_tmp.groupby(['object_id', 'passband'])['flux_err'].min().unstack(level='passband').add_suffix('_err_min')  # Min\n",
    "    flux_err_skew = df_tmp.groupby(['object_id', 'passband'])['flux_err'].skew().unstack(level='passband').add_suffix('_err_skew')  # Skew\n",
    "    flux_err_kurtosis = df_tmp.groupby(['object_id', 'passband'])['flux_err'].apply(pd.DataFrame.kurtosis).unstack(level='passband').add_suffix('_err_kurtosis')  # Kurtosis\n",
    "\n",
    "    df_out = df_out.join(flux_mean, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_median, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_std, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_max, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_min, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_skew, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_kurtosis, on='object_id', how='inner')\n",
    "\n",
    "    df_out = df_out.join(flux_err_mean, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_err_median, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_err_std, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_err_max, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_err_min, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_err_skew, on='object_id', how='inner')\n",
    "    df_out = df_out.join(flux_err_kurtosis, on='object_id', how='inner')\n",
    "\n",
    "    '''\n",
    "    detected - by object_id\n",
    "    '''\n",
    "    detected_mean = df_tmp.groupby(['object_id'])['detected'].mean()  # Mean (NOTE FIGURE OUT HOW TO ADD '_MEAN' to DF)\n",
    "    \n",
    "    df_out = df_out.join(detected_mean, on='object_id', how='inner', rsuffix='_mean')\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    flux_ratio_sq - by object_id\n",
    "    '''\n",
    "    ## By object_id\n",
    "    flux_rs_mean = df_tmp.groupby(['object_id'])['flux_ratio_sq'].mean()  # Mean (NOTE FIGURE OUT HOW TO ADD '_MEAN' to DF)\n",
    "    flux_rs_median = df_tmp.groupby(['object_id'])['flux_ratio_sq'].median() # Median\n",
    "    flux_rs_std = df_tmp.groupby(['object_id'])['flux_ratio_sq'].std()  # Std. Dev.\n",
    "    flux_rs_max = df_tmp.groupby(['object_id'])['flux_ratio_sq'].max()  # Max\n",
    "    flux_rs_min = df_tmp.groupby(['object_id'])['flux_ratio_sq'].min()  # Min\n",
    "    flux_rs_skew = df_tmp.groupby(['object_id'])['flux_ratio_sq'].skew()  # Skew\n",
    "    flux_rs_kurtosis = df_tmp.groupby(['object_id'])['flux_ratio_sq'].apply(pd.DataFrame.kurtosis)  # Kurtosis\n",
    "    flux_rs_sum = df_tmp.groupby(['object_id'])['flux_ratio_sq'].sum()  # Sum\n",
    "    \n",
    "    df_out = df_out.join(flux_rs_mean, on='object_id', how='inner', rsuffix='_mean')\n",
    "    df_out = df_out.join(flux_rs_median, on='object_id', how='inner', rsuffix='_median')\n",
    "    df_out = df_out.join(flux_rs_std, on='object_id', how='inner', rsuffix='_std')\n",
    "    df_out = df_out.join(flux_rs_max, on='object_id', how='inner', rsuffix='_max')\n",
    "    df_out = df_out.join(flux_rs_min, on='object_id', how='inner', rsuffix='_min')\n",
    "    df_out = df_out.join(flux_rs_skew, on='object_id', how='inner', rsuffix='_skew')\n",
    "    df_out = df_out.join(flux_rs_kurtosis, on='object_id', how='inner', rsuffix='_kurtosis')\n",
    "    df_out = df_out.join(flux_rs_sum, on='object_id', how='inner', rsuffix='_sum')\n",
    "    \n",
    "    '''\n",
    "    flux_by_flux_ratio_sq - by object_id\n",
    "    '''\n",
    "    ## By object_id\n",
    "    flux_bfrs_mean = df_tmp.groupby(['object_id'])['flux_by_flux_ratio_sq'].mean()  # Mean (NOTE FIGURE OUT HOW TO ADD '_MEAN' to DF)\n",
    "    flux_bfrs_median = df_tmp.groupby(['object_id'])['flux_by_flux_ratio_sq'].median() # Median\n",
    "    flux_bfrs_std = df_tmp.groupby(['object_id'])['flux_by_flux_ratio_sq'].std()  # Std. Dev.\n",
    "    flux_bfrs_max = df_tmp.groupby(['object_id'])['flux_by_flux_ratio_sq'].max()  # Max\n",
    "    flux_bfrs_min = df_tmp.groupby(['object_id'])['flux_by_flux_ratio_sq'].min()  # Min\n",
    "    flux_bfrs_skew = df_tmp.groupby(['object_id'])['flux_by_flux_ratio_sq'].skew()  # Skew\n",
    "    flux_bfrs_kurtosis = df_tmp.groupby(['object_id'])['flux_by_flux_ratio_sq'].apply(pd.DataFrame.kurtosis)  # Kurtosis\n",
    "    flux_bfrs_sum = df_tmp.groupby(['object_id'])['flux_by_flux_ratio_sq'].sum()  # Sum\n",
    "    \n",
    "    df_out = df_out.join(flux_bfrs_mean, on='object_id', how='inner', rsuffix='_mean')\n",
    "    df_out = df_out.join(flux_bfrs_median, on='object_id', how='inner', rsuffix='_median')\n",
    "    df_out = df_out.join(flux_bfrs_std, on='object_id', how='inner', rsuffix='_std')\n",
    "    df_out = df_out.join(flux_bfrs_max, on='object_id', how='inner', rsuffix='_max')\n",
    "    df_out = df_out.join(flux_bfrs_min, on='object_id', how='inner', rsuffix='_min')\n",
    "    df_out = df_out.join(flux_bfrs_skew, on='object_id', how='inner', rsuffix='_skew')\n",
    "    df_out = df_out.join(flux_bfrs_kurtosis, on='object_id', how='inner', rsuffix='_kurtosis')\n",
    "    df_out = df_out.join(flux_bfrs_sum, on='object_id', how='inner', rsuffix='_sum')\n",
    "    \n",
    "    '''\n",
    "    Diff Features\n",
    "    '''\n",
    "    df_out['flux_diff'] = df_out['flux_max'] - df_out['flux_min']\n",
    "    df_out['flux_diff_mean'] = (df_out['flux_max'] - df_out['flux_min'])/df_out['flux']\n",
    "    df_out['flux_w_mean'] = df_out['flux_by_flux_ratio_sq_sum'] / df_out['flux_ratio_sq_sum']\n",
    "    df_out['flux_diff_w_mean'] = (df_out['flux_max'] - df_out['flux_min'])/df_out['flux_w_mean']\n",
    "    \n",
    "    '''\n",
    "    Single Features\n",
    "    '''\n",
    "    # mjd_det_diff to separate \"one event\" objects as supernovae from \"cyclic event\" objects as cepheids.\n",
    "    df_det = df_tmp[df_tmp['detected']==1].copy()\n",
    "    gr_mjd = df_det.groupby('object_id').mjd\n",
    "    df_out['mjd_det_diff']  = gr_mjd.transform('max') - gr_mjd.transform('min')\n",
    "    df_out['mjd_det_diff'] = df_out['mjd_det_diff'].fillna(1000)  # 1000 is arbitrary number for not detected\n",
    "    \n",
    "    \n",
    "    # Interpret NaN to be 0\n",
    "    for c in df_out.columns:\n",
    "        df_out[c] = df_out[c].fillna(0)\n",
    "    \n",
    "    df_out['object_id'] = df_out['object_id'].astype(int)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['object_id', 'ra', 'decl', 'gal_l', 'gal_b', 'ddf', 'distmod', 'mwebv',\n",
      "       'target', 'hostgal_z',\n",
      "       ...\n",
      "       'flux_by_flux_ratio_sq_max', 'flux_by_flux_ratio_sq_min',\n",
      "       'flux_by_flux_ratio_sq_skew', 'flux_by_flux_ratio_sq_kurtosis',\n",
      "       'flux_by_flux_ratio_sq_sum', 'flux_diff', 'flux_diff_mean',\n",
      "       'flux_w_mean', 'flux_diff_w_mean', 'mjd_det_diff'],\n",
      "      dtype='object', length=132)\n",
      "object_id                         6.150000e+02\n",
      "ra                                3.490461e+02\n",
      "decl                             -6.194384e+01\n",
      "gal_l                             3.207965e+02\n",
      "gal_b                            -5.175371e+01\n",
      "ddf                               1.000000e+00\n",
      "distmod                           3.199610e+01\n",
      "mwebv                             1.700000e-02\n",
      "target                            9.200000e+01\n",
      "hostgal_z                         0.000000e+00\n",
      "haversine                         3.190063e-01\n",
      "latlon1                          -1.528827e+00\n",
      "flux                             -1.230970e+02\n",
      "flux_median                      -8.947752e+01\n",
      "flux_std                          3.941099e+02\n",
      "flux_max                          6.606263e+02\n",
      "flux_min                         -1.100440e+03\n",
      "flux_skew                        -3.495403e-01\n",
      "flux_kurtosis                    -2.598229e-01\n",
      "flux_err                          4.482743e+00\n",
      "flux_err_median                   3.835269e+00\n",
      "flux_err_std                      1.744747e+00\n",
      "flux_err_max                      1.284547e+01\n",
      "flux_err_min                      2.130510e+00\n",
      "flux_err_skew                     1.623740e+00\n",
      "flux_err_kurtosis                 2.582052e+00\n",
      "0_mean                           -3.254554e+00\n",
      "1_mean                           -3.856999e+02\n",
      "2_mean                           -1.341466e+02\n",
      "3_mean                           -1.211035e+02\n",
      "                                      ...     \n",
      "4_err_skew                        6.135947e+00\n",
      "5_err_skew                        1.530410e+00\n",
      "0_err_kurtosis                   -8.948205e-01\n",
      "1_err_kurtosis                   -1.314905e+00\n",
      "2_err_kurtosis                   -1.085405e+00\n",
      "3_err_kurtosis                   -3.616966e-01\n",
      "4_err_kurtosis                    4.306671e+01\n",
      "5_err_kurtosis                    3.263561e+00\n",
      "detected                          9.460227e-01\n",
      "flux_ratio_sq                     8.322924e+03\n",
      "flux_ratio_sq_median              4.104456e+03\n",
      "flux_ratio_sq_std                 8.802369e+03\n",
      "flux_ratio_sq_max                 2.848694e+04\n",
      "flux_ratio_sq_min                 1.868938e-01\n",
      "flux_ratio_sq_skew                8.127219e-01\n",
      "flux_ratio_sq_kurtosis           -7.131200e-01\n",
      "flux_ratio_sq_sum                 2.929669e+06\n",
      "flux_by_flux_ratio_sq            -2.727774e+06\n",
      "flux_by_flux_ratio_sq_median     -4.915929e+04\n",
      "flux_by_flux_ratio_sq_std         7.935039e+06\n",
      "flux_by_flux_ratio_sq_max         1.500205e+07\n",
      "flux_by_flux_ratio_sq_min        -2.963473e+07\n",
      "flux_by_flux_ratio_sq_skew       -1.414322e+00\n",
      "flux_by_flux_ratio_sq_kurtosis    2.488978e+00\n",
      "flux_by_flux_ratio_sq_sum        -9.601766e+08\n",
      "flux_diff                         1.761066e+03\n",
      "flux_diff_mean                   -1.430633e+01\n",
      "flux_w_mean                      -3.277423e+02\n",
      "flux_diff_w_mean                 -5.373326e+00\n",
      "mjd_det_diff                      8.737903e+02\n",
      "Name: 0, Length: 132, dtype: float64\n",
      "CPU times: user 48.9 s, sys: 967 ms, total: 49.8 s\n",
      "Wall time: 42.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv('../data/raw/training_set.csv')  # 1 gigs\n",
    "df_meta = pd.read_csv('../data/cleaned/training_meta_clean.csv')\n",
    "\n",
    "df_meta = generate_meta_features(df_meta)\n",
    "df_train = generate_features(df, df_meta)\n",
    "\n",
    "df_train.to_csv('../data/interim/training_fe.csv', index=False)\n",
    "\n",
    "print(df_train.columns)\n",
    "print(df_train.iloc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "182it [5:13:04, 96.61s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492890\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>ra</th>\n",
       "      <th>decl</th>\n",
       "      <th>gal_l</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>ddf</th>\n",
       "      <th>distmod</th>\n",
       "      <th>mwebv</th>\n",
       "      <th>hostgal_z</th>\n",
       "      <th>haversine</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_by_flux_ratio_sq_max</th>\n",
       "      <th>flux_by_flux_ratio_sq_min</th>\n",
       "      <th>flux_by_flux_ratio_sq_skew</th>\n",
       "      <th>flux_by_flux_ratio_sq_kurtosis</th>\n",
       "      <th>flux_by_flux_ratio_sq_sum</th>\n",
       "      <th>flux_diff</th>\n",
       "      <th>flux_diff_mean</th>\n",
       "      <th>flux_w_mean</th>\n",
       "      <th>flux_diff_w_mean</th>\n",
       "      <th>mjd_det_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>34.453125</td>\n",
       "      <td>-5.229529</td>\n",
       "      <td>169.987075</td>\n",
       "      <td>-59.956185</td>\n",
       "      <td>1</td>\n",
       "      <td>41.1123</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>1.851382</td>\n",
       "      <td>...</td>\n",
       "      <td>1.907738e+04</td>\n",
       "      <td>-41.837235</td>\n",
       "      <td>5.396523</td>\n",
       "      <td>31.557895</td>\n",
       "      <td>1.896346e+05</td>\n",
       "      <td>55.445738</td>\n",
       "      <td>13.871398</td>\n",
       "      <td>24.292155</td>\n",
       "      <td>2.282455</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>33.398438</td>\n",
       "      <td>-4.331149</td>\n",
       "      <td>167.226341</td>\n",
       "      <td>-59.936551</td>\n",
       "      <td>1</td>\n",
       "      <td>42.8774</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>1.855173</td>\n",
       "      <td>...</td>\n",
       "      <td>1.914014e+03</td>\n",
       "      <td>-30.436253</td>\n",
       "      <td>12.348124</td>\n",
       "      <td>156.645277</td>\n",
       "      <td>5.525817e+03</td>\n",
       "      <td>25.981591</td>\n",
       "      <td>29.389389</td>\n",
       "      <td>6.852393</td>\n",
       "      <td>3.791608</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>348.529419</td>\n",
       "      <td>-61.755440</td>\n",
       "      <td>321.293980</td>\n",
       "      <td>-51.763351</td>\n",
       "      <td>1</td>\n",
       "      <td>43.6000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.8297</td>\n",
       "      <td>0.309914</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088702e+03</td>\n",
       "      <td>-109.941461</td>\n",
       "      <td>9.923556</td>\n",
       "      <td>119.717988</td>\n",
       "      <td>4.124400e+03</td>\n",
       "      <td>30.964024</td>\n",
       "      <td>39.143819</td>\n",
       "      <td>5.255113</td>\n",
       "      <td>5.892170</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>34.804688</td>\n",
       "      <td>-5.829153</td>\n",
       "      <td>171.307861</td>\n",
       "      <td>-60.174401</td>\n",
       "      <td>1</td>\n",
       "      <td>42.9640</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.6533</td>\n",
       "      <td>1.845038</td>\n",
       "      <td>...</td>\n",
       "      <td>2.208811e+03</td>\n",
       "      <td>-69.335479</td>\n",
       "      <td>9.227223</td>\n",
       "      <td>93.100472</td>\n",
       "      <td>8.293673e+03</td>\n",
       "      <td>40.693061</td>\n",
       "      <td>41.934474</td>\n",
       "      <td>9.467365</td>\n",
       "      <td>4.298245</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>351.321442</td>\n",
       "      <td>-64.198746</td>\n",
       "      <td>317.458993</td>\n",
       "      <td>-50.429931</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0540</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.391772</td>\n",
       "      <td>...</td>\n",
       "      <td>1.365432e+06</td>\n",
       "      <td>-51.048373</td>\n",
       "      <td>10.251332</td>\n",
       "      <td>117.972119</td>\n",
       "      <td>4.815012e+06</td>\n",
       "      <td>137.715186</td>\n",
       "      <td>30.068359</td>\n",
       "      <td>101.128982</td>\n",
       "      <td>1.361778</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id          ra       decl       gal_l      gal_b  ddf  distmod  \\\n",
       "0         13   34.453125  -5.229529  169.987075 -59.956185    1  41.1123   \n",
       "1         14   33.398438  -4.331149  167.226341 -59.936551    1  42.8774   \n",
       "2         17  348.529419 -61.755440  321.293980 -51.763351    1  43.6000   \n",
       "3         23   34.804688  -5.829153  171.307861 -60.174401    1  42.9640   \n",
       "4         34  351.321442 -64.198746  317.458993 -50.429931    1  42.0540   \n",
       "\n",
       "   mwebv  hostgal_z  haversine      ...       flux_by_flux_ratio_sq_max  \\\n",
       "0  0.019     0.3048   1.851382      ...                    1.907738e+04   \n",
       "1  0.018     0.6323   1.855173      ...                    1.914014e+03   \n",
       "2  0.016     0.8297   0.309914      ...                    1.088702e+03   \n",
       "3  0.023     0.6533   1.845038      ...                    2.208811e+03   \n",
       "4  0.023     0.4557   0.391772      ...                    1.365432e+06   \n",
       "\n",
       "   flux_by_flux_ratio_sq_min  flux_by_flux_ratio_sq_skew  \\\n",
       "0                 -41.837235                    5.396523   \n",
       "1                 -30.436253                   12.348124   \n",
       "2                -109.941461                    9.923556   \n",
       "3                 -69.335479                    9.227223   \n",
       "4                 -51.048373                   10.251332   \n",
       "\n",
       "   flux_by_flux_ratio_sq_kurtosis  flux_by_flux_ratio_sq_sum   flux_diff  \\\n",
       "0                       31.557895               1.896346e+05   55.445738   \n",
       "1                      156.645277               5.525817e+03   25.981591   \n",
       "2                      119.717988               4.124400e+03   30.964024   \n",
       "3                       93.100472               8.293673e+03   40.693061   \n",
       "4                      117.972119               4.815012e+06  137.715186   \n",
       "\n",
       "   flux_diff_mean  flux_w_mean  flux_diff_w_mean  mjd_det_diff  \n",
       "0       13.871398    24.292155          2.282455        1000.0  \n",
       "1       29.389389     6.852393          3.791608        1000.0  \n",
       "2       39.143819     5.255113          5.892170        1000.0  \n",
       "3       41.934474     9.467365          4.298245        1000.0  \n",
       "4       30.068359   101.128982          1.361778        1000.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_test = pd.read_csv('../data/cleaned/testing_meta_clean.csv')\n",
    "df_meta_test = generate_meta_features(df_meta_test)\n",
    "\n",
    "# NOTE: Sort test set first\n",
    "\n",
    "df_test = pd.DataFrame()\n",
    "chunks = 2500000\n",
    "remain_df = None\n",
    "for i, df_chunk in tqdm(enumerate(pd.read_csv('../data/processed/test_set_sorted.csv', chunksize=chunks, iterator=True))):\n",
    "    # Check object_ids\n",
    "    # I believe np.unique keeps the order of group_ids as they appear in the file\n",
    "    unique_ids = np.unique(df_chunk['object_id'])\n",
    "\n",
    "    new_remain_df = df_chunk.loc[df_chunk['object_id'] == unique_ids[-1]].copy()\n",
    "    if remain_df is None:\n",
    "        df_chunk = df_chunk.loc[df_chunk['object_id'].isin(unique_ids[:-1])]\n",
    "    else:\n",
    "        df_chunk = pd.concat([remain_df, df_chunk.loc[df_chunk['object_id'].isin(unique_ids[:-1])]], axis=0)\n",
    "    # Create remaining samples df\n",
    "    remain_df = new_remain_df\n",
    "\n",
    "    df_tmp = generate_features(df_chunk, df_meta_test)\n",
    "    if i == 0:\n",
    "        df_test = df_tmp\n",
    "    else:\n",
    "        df_test = pd.concat([df_test, df_tmp], sort=False)\n",
    "        \n",
    "    del df_tmp\n",
    "\n",
    "# process rest\n",
    "df_tmp = generate_features(remain_df, df_meta_test)\n",
    "df_test = pd.concat([df_test, df_tmp], sort=False)\n",
    "del df_tmp\n",
    "\n",
    "df_test.to_csv('../data/interim/testing_fe.csv', index=False)\n",
    "\n",
    "print(len(df_test)) #should be 3492890\n",
    "\n",
    "df_test.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial 2 (Not better with meta, try later with time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train\n",
    "# id_features = df_meta[['object_id', 'ddf', 'target']]\n",
    "# df_meta = df_meta.drop(['object_id', 'ddf', 'target'], axis=1)\n",
    "\n",
    "# poly = PolynomialFeatures(2, include_bias=False)\n",
    "# poly_output = poly.fit_transform(df_meta)\n",
    "# target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(df_meta.columns,p) for p in poly.powers_]]\n",
    "# df_meta = pd.DataFrame(poly_output, columns = target_feature_names)\n",
    "\n",
    "# df_meta = pd.concat([id_features, df_meta],axis=1)\n",
    "\n",
    "# # Test\n",
    "# id_features = df_meta_test[['object_id', 'ddf']]\n",
    "# df_meta_test = df_meta_test.drop(['object_id', 'ddf'], axis=1)\n",
    "\n",
    "# poly = PolynomialFeatures(2, include_bias=False)\n",
    "# poly_output = poly.fit_transform(df_meta_test)\n",
    "# target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(df_meta_test.columns,p) for p in poly.powers_]]\n",
    "# df_meta_test = pd.DataFrame(poly_output, columns = target_feature_names)\n",
    "\n",
    "# df_meta_test = pd.concat([id_features, df_meta_test],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
